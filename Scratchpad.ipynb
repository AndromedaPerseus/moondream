{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikhyat/Coding/moondream/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from moondream.modeling_phi import apply_rotary_pos_emb\n",
    "\n",
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2024-04-02\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, trust_remote_code=True, revision=revision, torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"Describe the image.\", return_tensors=\"pt\")['input_ids']\n",
    "inputs_embeds = model.text_model.get_input_embeddings()(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1456,  0.5635,  0.6240,  ...,  0.4666,  0.2549, -0.2764],\n",
       "         [ 0.6284,  0.3845,  0.8750,  ...,  0.9077,  0.0452, -0.3027],\n",
       "         [ 0.3618,  0.6597,  0.6064,  ...,  0.4902,  0.1268, -0.3398],\n",
       "         [ 0.1552,  0.3916,  0.4509,  ...,  0.1307, -0.0458, -0.0320],\n",
       "         [ 0.0200,  0.0423, -0.5195,  ...,  0.1262,  0.0666, -0.0076]]],\n",
       "       dtype=torch.float16, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = inputs_embeds\n",
    "x = model.text_model.transformer.h[0].ln(x)\n",
    "\n",
    "# Attention\n",
    "mixer = model.text_model.transformer.h[0].mixer\n",
    "bsz, q_len, _ = x.size()\n",
    "query_states, key_states, value_states = mixer.Wqkv(x).chunk(3, dim=-1)\n",
    "query_states = query_states.view(\n",
    "    bsz, q_len, mixer.num_heads, mixer.head_dim\n",
    ").transpose(1, 2)\n",
    "key_states = key_states.view(\n",
    "    bsz, q_len, mixer.num_key_value_heads, mixer.head_dim\n",
    ").transpose(1, 2)\n",
    "value_states = value_states.view(\n",
    "    bsz, q_len, mixer.num_key_value_heads, mixer.head_dim\n",
    ").transpose(1, 2)\n",
    "\n",
    "# rope\n",
    "kv_seq_len = key_states.shape[-2]\n",
    "cos, sin = mixer.rotary_emb(value_states, seq_len=kv_seq_len)\n",
    "query_rot, query_pass = (\n",
    "    query_states[..., : mixer.rotary_emb.dim],\n",
    "    query_states[..., mixer.rotary_emb.dim :],\n",
    ")\n",
    "key_rot, key_pass = (\n",
    "    key_states[..., : mixer.rotary_emb.dim],\n",
    "    key_states[..., mixer.rotary_emb.dim :],\n",
    ")\n",
    "query_rot, key_rot = apply_rotary_pos_emb(\n",
    "    query_rot, key_rot, cos, sin, None\n",
    ")\n",
    "query_states = torch.cat((query_rot, query_pass), dim=-1)\n",
    "key_states = torch.cat((key_rot, key_pass), dim=-1)\n",
    "\n",
    "attn_output = scaled_dot_product_attention(\n",
    "    query_states, key_states, value_states, is_causal=True\n",
    ")\n",
    "attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "attn_output = attn_output.reshape(bsz, q_len, mixer.hidden_size)\n",
    "attn_output = mixer.out_proj(attn_output)\n",
    "\n",
    "print(attn_output.shape)\n",
    "attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, attn_mask=None, dropout_p=0.0, is_causal=False, scale=None) -> torch.Tensor:\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "    attn_bias = torch.zeros(L, S, dtype=query.dtype)\n",
    "    if is_causal:\n",
    "        assert attn_mask is None\n",
    "        temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal=0)\n",
    "        attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "        attn_bias.to(query.dtype)\n",
    "\n",
    "    if attn_mask is not None:\n",
    "        if attn_mask.dtype == torch.bool:\n",
    "            attn_bias.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "        else:\n",
    "            attn_bias += attn_mask\n",
    "    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "    attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "    attn_weight = torch.dropout(attn_weight, dropout_p, train=True)\n",
    "    return attn_weight @ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Is this a dog? Yes or no.\\n\\nAnswer: No\\n\\n4. Is this a cat or a dog? No\\n\\n5. Is this a cat or a dog? No\\n\\n6. Is'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(\"Question: Is this a dog? Yes or no.\\n\\nAnswer:\", return_tensors=\"pt\")['input_ids']\n",
    "output = model.text_model.generate(tokens, do_sample=False, max_length=50, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
